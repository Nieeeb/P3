Using device: cpu
Scattering Flare Image: Flare7K  is loaded successfully with  5000  flares
Scattering Flare Image: Flare7K  is loaded successfully with  5000  flares
tensor([[[[0.5158, 0.5094, 0.5178,  ..., 0.5312, 0.5207, 0.5300],
          [0.5240, 0.5075, 0.5151,  ..., 0.5216, 0.5323, 0.5245],
          [0.5053, 0.5028, 0.5197,  ..., 0.5083, 0.5194, 0.5196],
          ...,
          [0.5122, 0.5179, 0.5214,  ..., 0.5060, 0.5172, 0.5237],
          [0.5249, 0.5305, 0.5339,  ..., 0.5253, 0.5194, 0.5134],
          [0.5142, 0.5100, 0.5191,  ..., 0.5132, 0.5274, 0.5206]],

         [[0.4895, 0.4852, 0.4965,  ..., 0.4942, 0.4914, 0.4753],
          [0.4914, 0.5086, 0.5015,  ..., 0.4916, 0.4900, 0.4789],
          [0.4950, 0.4934, 0.4766,  ..., 0.4917, 0.4867, 0.4847],
          ...,
          [0.4951, 0.4917, 0.4949,  ..., 0.4948, 0.4817, 0.4892],
          [0.4824, 0.4824, 0.4893,  ..., 0.4897, 0.4829, 0.4879],
          [0.4731, 0.4914, 0.4928,  ..., 0.4770, 0.4859, 0.4903]],

         [[0.5131, 0.4968, 0.5204,  ..., 0.5282, 0.5256, 0.5175],
          [0.5151, 0.4902, 0.4994,  ..., 0.5133, 0.5163, 0.5139],
          [0.5110, 0.4949, 0.5027,  ..., 0.4923, 0.5102, 0.4935],
          ...,
          [0.4980, 0.5039, 0.4951,  ..., 0.5151, 0.5134, 0.5019],
          [0.5142, 0.5160, 0.4949,  ..., 0.5016, 0.4988, 0.4873],
          [0.5054, 0.5101, 0.5164,  ..., 0.4900, 0.4978, 0.4996]]],


        [[[0.5113, 0.5306, 0.5215,  ..., 0.5148, 0.5167, 0.5202],
          [0.5258, 0.5096, 0.5232,  ..., 0.5035, 0.5068, 0.5179],
          [0.5183, 0.4969, 0.5216,  ..., 0.5011, 0.5098, 0.5214],
          ...,
          [0.5147, 0.5160, 0.5190,  ..., 0.5131, 0.5144, 0.5201],
          [0.5245, 0.5306, 0.5348,  ..., 0.5263, 0.5256, 0.5253],
          [0.5160, 0.5088, 0.5175,  ..., 0.5175, 0.5233, 0.5167]],

         [[0.4818, 0.4912, 0.5049,  ..., 0.4889, 0.4850, 0.4804],
          [0.4693, 0.5100, 0.4889,  ..., 0.4983, 0.4820, 0.4878],
          [0.4952, 0.4845, 0.4929,  ..., 0.5118, 0.4857, 0.4766],
          ...,
          [0.5043, 0.5005, 0.5054,  ..., 0.4852, 0.4738, 0.4779],
          [0.4872, 0.4857, 0.4873,  ..., 0.4872, 0.4934, 0.4874],
          [0.4784, 0.4915, 0.4897,  ..., 0.4950, 0.5035, 0.4883]],

         [[0.5066, 0.4989, 0.5062,  ..., 0.5160, 0.5065, 0.5098],
          [0.5165, 0.5038, 0.5315,  ..., 0.5070, 0.5078, 0.5065],
          [0.5073, 0.4963, 0.5163,  ..., 0.4861, 0.5045, 0.5079],
          ...,
          [0.4963, 0.4891, 0.4881,  ..., 0.4950, 0.5038, 0.5050],
          [0.5098, 0.5109, 0.4972,  ..., 0.5036, 0.5173, 0.5053],
          [0.5068, 0.5152, 0.5193,  ..., 0.5056, 0.5120, 0.5096]]],


        [[[0.5159, 0.5192, 0.5227,  ..., 0.5213, 0.5129, 0.5257],
          [0.5251, 0.5183, 0.5200,  ..., 0.5003, 0.5045, 0.5224],
          [0.5112, 0.5071, 0.5254,  ..., 0.5093, 0.5142, 0.5261],
          ...,
          [0.5156, 0.5164, 0.5197,  ..., 0.5956, 0.5980, 0.6023],
          [0.5269, 0.5287, 0.5361,  ..., 0.6211, 0.6267, 0.6177],
          [0.5212, 0.5109, 0.5138,  ..., 0.6027, 0.5863, 0.5538]],

         [[0.4917, 0.5028, 0.4988,  ..., 0.4934, 0.4802, 0.4747],
          [0.4855, 0.5039, 0.4866,  ..., 0.4989, 0.4788, 0.4807],
          [0.4860, 0.4987, 0.4945,  ..., 0.5110, 0.4850, 0.4706],
          ...,
          [0.4966, 0.4868, 0.4982,  ..., 0.5010, 0.5162, 0.5006],
          [0.4895, 0.4785, 0.4892,  ..., 0.5209, 0.5201, 0.4830],
          [0.4801, 0.4952, 0.4898,  ..., 0.5180, 0.5004, 0.4598]],

         [[0.5123, 0.5001, 0.5016,  ..., 0.5091, 0.5102, 0.5131],
          [0.5150, 0.5218, 0.5260,  ..., 0.5029, 0.5144, 0.5089],
          [0.5127, 0.5121, 0.5448,  ..., 0.4984, 0.5101, 0.5144],
          ...,
          [0.4980, 0.4977, 0.4963,  ..., 0.5661, 0.5714, 0.5471],
          [0.5019, 0.5017, 0.4944,  ..., 0.5852, 0.5493, 0.5375],
          [0.5049, 0.5077, 0.5103,  ..., 0.5596, 0.5485, 0.5128]]],


        [[[0.5153, 0.5190, 0.5207,  ..., 0.5151, 0.5154, 0.5256],
          [0.5262, 0.5194, 0.5268,  ..., 0.5030, 0.5050, 0.5243],
          [0.5053, 0.5163, 0.5316,  ..., 0.5109, 0.5082, 0.5258],
          ...,
          [0.5176, 0.5194, 0.5211,  ..., 0.5116, 0.5145, 0.5210],
          [0.5280, 0.5325, 0.5428,  ..., 0.5297, 0.5298, 0.5237],
          [0.5206, 0.5162, 0.5202,  ..., 0.5205, 0.5259, 0.5174]],

         [[0.4880, 0.4985, 0.4984,  ..., 0.4931, 0.4880, 0.4761],
          [0.4832, 0.5053, 0.4726,  ..., 0.5003, 0.4838, 0.4857],
          [0.4806, 0.5121, 0.5005,  ..., 0.5115, 0.4897, 0.4770],
          ...,
          [0.4942, 0.4857, 0.4874,  ..., 0.4831, 0.4808, 0.4813],
          [0.4910, 0.4804, 0.4909,  ..., 0.4863, 0.4949, 0.4909],
          [0.4826, 0.4947, 0.4921,  ..., 0.4930, 0.4976, 0.4893]],

         [[0.5148, 0.5102, 0.4993,  ..., 0.5155, 0.5164, 0.5156],
          [0.5186, 0.5259, 0.5308,  ..., 0.5167, 0.5158, 0.5210],
          [0.5112, 0.5074, 0.5355,  ..., 0.4936, 0.5102, 0.5159],
          ...,
          [0.4954, 0.5010, 0.5055,  ..., 0.4963, 0.5033, 0.5081],
          [0.5096, 0.5054, 0.5092,  ..., 0.5059, 0.5137, 0.5052],
          [0.5002, 0.5112, 0.5153,  ..., 0.5093, 0.5136, 0.5106]]]],
       grad_fn=<SigmoidBackward0>)
tensor(nan, grad_fn=<MeanBackward0>)
tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], grad_fn=<SigmoidBackward0>)
tensor(nan, grad_fn=<MeanBackward0>)
tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], grad_fn=<SigmoidBackward0>)
tensor(nan, grad_fn=<MeanBackward0>)
Traceback (most recent call last):
  File "c:\Users\Victor Steinrud\Documents\DAKI\3. semester\P3\Modules\train.py", line 163, in <module>
    train(model_name, optimizer_name, preprocessing_name, preprocessing_size, dataset_name, output_path, loss, batch_size)
  File "c:\Users\Victor Steinrud\Documents\DAKI\3. semester\P3\Modules\train.py", line 76, in train
    loss.backward()
  File "C:\Users\Victor Steinrud\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\_tensor.py", line 521, in backward
    torch.autograd.backward(
  File "C:\Users\Victor Steinrud\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\autograd\__init__.py", line 289, in backward
    _engine_run_backward(
  File "C:\Users\Victor Steinrud\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torch\autograd\graph.py", line 769, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
